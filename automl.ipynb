{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "## Overview\n",
        "\n",
        "For this notebook we will be importing the dataset, creating an experiment, creating a compute cluster, running the AutoML Experiment and selecting the best AutoML Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\r\n",
        "\r\n",
        "Importing all the needed dependencies to complete the project"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import csv\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn import datasets\r\n",
        "import pkg_resources\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.27.0\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1620323296616
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workspace Configuration\n",
        "\n",
        "In this cell we import the workspace configuration and create an experiment that we will use later."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'automlcovid'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-144102\n",
            "Azure region: southcentralus\n",
            "Subscription id: a24a24d5-8d87-4c8a-99b6-91ed2d2df51f\n",
            "Resource group: aml-quickstarts-144102\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Experiment(Name: automlcovid,\nWorkspace: quick-starts-ws-144102)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automlcovid</td><td>quick-starts-ws-144102</td><td><a href=\"https://ml.azure.com/experiments/id/aa426b34-f0a7-4ac4-8faa-307297b4045b?wsid=/subscriptions/a24a24d5-8d87-4c8a-99b6-91ed2d2df51f/resourcegroups/aml-quickstarts-144102/workspaces/quick-starts-ws-144102&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1620323300891
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Cluster creation\r\n",
        "In this cell a cpu cluster is created for running our experiments, it checks if a compute cluster with the same name exists, if it exists then uses if, if not it creates it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "compute_cluster_name = \"cpu-cluster\"\r\n",
        "\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_cluster_name)\r\n",
        "    print(\"Found existing compute cluster...\")\r\n",
        "except:\r\n",
        "    print(\"Creating new compute cluster...\")\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\r\n",
        "    compute_target = ComputeTarget.create(ws, compute_cluster_name, compute_config)\r\n",
        "    \r\n",
        "compute_target.wait_for_completion(show_output=True)\r\n",
        "print(\"Cluster details: \", compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute cluster...\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n",
            "Cluster details:  {'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-05-06T16:14:42.705000+00:00', 'errors': None, 'creationTime': '2021-05-06T16:14:40.188357+00:00', 'modifiedTime': '2021-05-06T16:14:55.535988+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620323304506
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\r\n",
        "\r\n",
        "### Overview\r\n",
        "We are going to use the Mexican Government's COVID-19 data, once it is uploaded to ML Studio we will consume it using TabularDataset.\r\n",
        "\r\n",
        "To consume the dataset we will import it from the Datastore tab in ML Studio, we have to specify the location of the csv and then we will import it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "from azureml.core import Datastore\r\n",
        "\r\n",
        "datastore = Datastore.get(ws,'workspaceblobstore')\r\n",
        "ds = TabularDatasetFactory.from_delimited_files(path=(datastore, 'UI/05-06-2021_035443_UTC/210505COVID19MEXICO.csv'))\r\n",
        "df = ds.to_pandas_dataframe()\r\n",
        "print(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        FECHA_ACTUALIZACION ID_REGISTRO  ORIGEN  SECTOR  ENTIDAD_UM  SEXO  \\\n",
            "0                2021-05-05      z482b8       1      12           9     2   \n",
            "1                2021-05-05      z49a69       1      12          23     1   \n",
            "2                2021-05-05      z23d9d       1      12          22     2   \n",
            "3                2021-05-05      z24953       1      12           9     1   \n",
            "4                2021-05-05      zz8e77       1      12           9     2   \n",
            "...                     ...         ...     ...     ...         ...   ...   \n",
            "6697731          2021-05-05      977f22       2      12           9     2   \n",
            "6697732          2021-05-05      9a7125       2       4          19     1   \n",
            "6697733          2021-05-05      a86b4e       1       4          31     2   \n",
            "6697734          2021-05-05      58438f       2       4          11     2   \n",
            "6697735          2021-05-05      6c86ad       2       4          19     2   \n",
            "\n",
            "         ENTIDAD_NAC  ENTIDAD_RES  MUNICIPIO_RES  TIPO_PACIENTE  ...  \\\n",
            "0                  9            9             12              1  ...   \n",
            "1                 23           23              4              2  ...   \n",
            "2                 24           22              9              1  ...   \n",
            "3                  9            9             10              1  ...   \n",
            "4                  9            9              2              1  ...   \n",
            "...              ...          ...            ...            ...  ...   \n",
            "6697731           15           15             29              1  ...   \n",
            "6697732           19           19             39              1  ...   \n",
            "6697733           31           31             50              2  ...   \n",
            "6697734           11           11             11              1  ...   \n",
            "6697735           19           19             18              1  ...   \n",
            "\n",
            "        OTRO_CASO TOMA_MUESTRA_LAB RESULTADO_LAB  TOMA_MUESTRA_ANTIGENO  \\\n",
            "0               2                2            97                      2   \n",
            "1               1                2            97                      2   \n",
            "2               2                2            97                      2   \n",
            "3               1                1             2                      2   \n",
            "4               2                2            97                      2   \n",
            "...           ...              ...           ...                    ...   \n",
            "6697731         2                2            97                      1   \n",
            "6697732         2                2            97                      1   \n",
            "6697733         2                2            97                      2   \n",
            "6697734         2                2            97                      1   \n",
            "6697735         2                2            97                      1   \n",
            "\n",
            "         RESULTADO_ANTIGENO  CLASIFICACION_FINAL  MIGRANTE  PAIS_NACIONALIDAD  \\\n",
            "0                        97                    1        99             México   \n",
            "1                        97                    2        99             México   \n",
            "2                        97                    6        99             México   \n",
            "3                        97                    7        99             México   \n",
            "4                        97                    6        99             México   \n",
            "...                     ...                  ...       ...                ...   \n",
            "6697731                   2                    7        99             México   \n",
            "6697732                   2                    7        99             México   \n",
            "6697733                  97                    6        99             México   \n",
            "6697734                   2                    7        99             México   \n",
            "6697735                   2                    7        99             México   \n",
            "\n",
            "         PAIS_ORIGEN  UCI  \n",
            "0               97.0   97  \n",
            "1               97.0    1  \n",
            "2               97.0   97  \n",
            "3               97.0   97  \n",
            "4               97.0   97  \n",
            "...              ...  ...  \n",
            "6697731         97.0   97  \n",
            "6697732         97.0   97  \n",
            "6697733         97.0    2  \n",
            "6697734         97.0   97  \n",
            "6697735         97.0   97  \n",
            "\n",
            "[6697736 rows x 40 columns]\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620323326925
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/test split\r\n",
        "\r\n",
        "We will divide the dataset between train and test"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train_data, test_data = train_test_split(df,test_size = 0.2, random_state = 42)\r\n",
        "label = 'UCI'"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620323334112
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Train Data to Tabular Dataset\r\n",
        "Since the train data is in the pandas Dataframe format, we have to convert it to Tabular Dataset to be used in AutoML"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert train_data (Which are in pandas DataFrame format) to TabularDataset format.\r\n",
        "try:\r\n",
        "    os.makedirs('./data', exist_ok=True)\r\n",
        "except OSError as error:\r\n",
        "    print('New directory cannot be created')\r\n",
        "    \r\n",
        "path = 'data/train.csv'\r\n",
        "train_data.to_csv(path)\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "datastore.upload(src_dir='data', target_path='data')\r\n",
        "\r\n",
        "train_data = TabularDatasetFactory.from_delimited_files(path=[(datastore, ('data/train.csv'))])\r\n",
        "print(\"Successfully converted the dataset to TabularDataset format.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Target already exists. Skipping upload for data/train.csv\n",
            "Uploaded 0 files\n",
            "Successfully converted the dataset to TabularDataset format.\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620323618249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_data))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'azureml.data.tabular_dataset.TabularDataset'>\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620323623320
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 30,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'accuracy'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target=compute_target,\n",
        "    task = \"classification\",\n",
        "    training_data=train_data,\n",
        "    label_column_name=label,   \n",
        "    enable_early_stopping= True,\n",
        "    featurization= 'auto',\n",
        "    debug_log = \"automl_errors.log\",\n",
        "    **automl_settings\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1620323632518
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config, show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting remote run.\n",
            "No run_configuration provided, running on cpu-cluster with default configuration\n",
            "Running on remote compute: cpu-cluster\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automlcovid</td><td>AutoML_a0888a02-8cec-4c9d-9962-5d41b4f0c373</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_a0888a02-8cec-4c9d-9962-5d41b4f0c373?wsid=/subscriptions/a24a24d5-8d87-4c8a-99b6-91ed2d2df51f/resourcegroups/aml-quickstarts-144102/workspaces/quick-starts-ws-144102&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Something went wrong while printing the experiment progress but the run is still executing on the compute target. \n",
            "Please check portal for updated status: https://ml.azure.com/runs/AutoML_a0888a02-8cec-4c9d-9962-5d41b4f0c373?wsid=/subscriptions/a24a24d5-8d87-4c8a-99b6-91ed2d2df51f/resourcegroups/aml-quickstarts-144102/workspaces/quick-starts-ws-144102&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1620325151844
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431425670
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431426111
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}