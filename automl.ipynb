{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "## Overview\n",
        "\n",
        "For this notebook we will be importing the dataset, creating an experiment, creating a compute cluster, cleanning and preprocessing the data before doing our train and test split, running the AutoML Experiment and selecting the best AutoML Model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "\n",
        "First we will be importing all the needed dependencies to complete the project.\n",
        "\n",
        "Warning: Install the `imblearn` library before running the rest of the notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imblearn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imblearn in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from imblearn) (0.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620610889162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core import Datastore\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.27.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1620619118589
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workspace Configuration\n",
        "\n",
        "In this cell we import the workspace configuration and create an experiment that we will use later."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'automlcovid'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-144339\n",
            "Azure region: southcentralus\n",
            "Subscription id: 9b72f9e6-56c5-4c16-991b-19c652994860\n",
            "Resource group: aml-quickstarts-144339\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "Experiment(Name: automlcovid,\nWorkspace: quick-starts-ws-144339)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automlcovid</td><td>quick-starts-ws-144339</td><td><a href=\"https://ml.azure.com/experiments/id/c13f55dc-d30a-458e-a073-56cb7a9ee877?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-144339/workspaces/quick-starts-ws-144339&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1620619122322
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Cluster creation\n",
        "In this cell a cpu cluster is created for running our experiments, it checks if a compute cluster with the same name exists, if it exists then uses it, if not it creates it.\n",
        "\n",
        "If the cluster does not exists we define the configuration for it. For this project we will be using `min_nodes = 1`, in your own project this will incurr in extra costs, so consider leaving it to 0."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_cluster_name = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=compute_cluster_name)\n",
        "    print(\"Found existing compute cluster...\")\n",
        "except:\n",
        "    print(\"Creating new compute cluster...\")\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D16s_V3', max_nodes=4, min_nodes=1)\n",
        "    compute_target = ComputeTarget.create(ws, compute_cluster_name, compute_config)\n",
        "    \n",
        "compute_target.wait_for_completion(show_output=True)\n",
        "print(\"Cluster details: \", compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute cluster...\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n",
            "Cluster details:  {'currentNodeCount': 4, 'targetNodeCount': 4, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 4, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-05-10T03:36:42.954000+00:00', 'errors': None, 'creationTime': '2021-05-10T01:43:20.670500+00:00', 'modifiedTime': '2021-05-10T01:43:36.013311+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 1, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D16S_V3'}\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619124261
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "We are going to use the Mexican Government's COVID-19 data, once it is uploaded to ML Studio we will consume it using TabularDataset.\n",
        "\n",
        "To consume the dataset we will import it from the Datastore tab in ML Studio, this is a blob storage, then we have to specify the location of the csv to import it.\n",
        "\n",
        "Once it's imported we will we creating a Pandas Dataframe that we will need later on."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = Datastore.get(ws,'workspaceblobstore')\n",
        "ds = TabularDatasetFactory.from_delimited_files(path=(datastore, 'UI/05-10-2021_013755_UTC/210509COVID19MEXICO.csv'))\n",
        "df = ds.to_pandas_dataframe()\n",
        "\n",
        "print(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        FECHA_ACTUALIZACION ID_REGISTRO  ORIGEN  SECTOR  ENTIDAD_UM  SEXO  \\\n",
            "0                2021-05-09      z482b8       1      12           9     2   \n",
            "1                2021-05-09      z49a69       1      12          23     1   \n",
            "2                2021-05-09      z23d9d       1      12          22     2   \n",
            "3                2021-05-09      z24953       1      12           9     1   \n",
            "4                2021-05-09      zz8e77       1      12           9     2   \n",
            "...                     ...         ...     ...     ...         ...   ...   \n",
            "6757355          2021-05-09      6bd21b       2      12           9     1   \n",
            "6757356          2021-05-09      d0d932       2      12          12     1   \n",
            "6757357          2021-05-09      7ceaf8       2       4           9     1   \n",
            "6757358          2021-05-09      56cd1e       2       4           5     1   \n",
            "6757359          2021-05-09      cd3ffd       2       4          15     2   \n",
            "\n",
            "         ENTIDAD_NAC  ENTIDAD_RES  MUNICIPIO_RES  TIPO_PACIENTE  ...  \\\n",
            "0                  9            9             12              1  ...   \n",
            "1                 23           23              4              2  ...   \n",
            "2                 24           22              9              1  ...   \n",
            "3                  9            9             10              1  ...   \n",
            "4                  9            9              2              1  ...   \n",
            "...              ...          ...            ...            ...  ...   \n",
            "6757355           15            9             11              1  ...   \n",
            "6757356           12           12              1              1  ...   \n",
            "6757357            9            9              7              1  ...   \n",
            "6757358            5            5             27              1  ...   \n",
            "6757359           15           15            106              1  ...   \n",
            "\n",
            "        OTRO_CASO TOMA_MUESTRA_LAB RESULTADO_LAB  TOMA_MUESTRA_ANTIGENO  \\\n",
            "0               2                2            97                      2   \n",
            "1               1                2            97                      2   \n",
            "2               2                2            97                      2   \n",
            "3               1                1             2                      2   \n",
            "4               2                2            97                      2   \n",
            "...           ...              ...           ...                    ...   \n",
            "6757355         2                2            97                      1   \n",
            "6757356         1                2            97                      1   \n",
            "6757357         2                2            97                      1   \n",
            "6757358         1                2            97                      1   \n",
            "6757359         2                2            97                      1   \n",
            "\n",
            "         RESULTADO_ANTIGENO  CLASIFICACION_FINAL  MIGRANTE  PAIS_NACIONALIDAD  \\\n",
            "0                        97                    1        99             México   \n",
            "1                        97                    2        99             México   \n",
            "2                        97                    6        99             México   \n",
            "3                        97                    7        99             México   \n",
            "4                        97                    6        99             México   \n",
            "...                     ...                  ...       ...                ...   \n",
            "6757355                   2                    7        99             México   \n",
            "6757356                   2                    7        99             México   \n",
            "6757357                   2                    7        99             México   \n",
            "6757358                   2                    7        99             México   \n",
            "6757359                   2                    7        99             México   \n",
            "\n",
            "         PAIS_ORIGEN  UCI  \n",
            "0               97.0   97  \n",
            "1               97.0    1  \n",
            "2               97.0   97  \n",
            "3               97.0   97  \n",
            "4               97.0   97  \n",
            "...              ...  ...  \n",
            "6757355         97.0   97  \n",
            "6757356         97.0   97  \n",
            "6757357         97.0   97  \n",
            "6757358         97.0   97  \n",
            "6757359         97.0   97  \n",
            "\n",
            "[6757360 rows x 40 columns]\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619146207
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "#### Cleaning\n",
        "The objective of our project is to create a model that can get if a patient with COVID-19 will enter into an Intensive Care Unit or not.\n",
        "\n",
        "The objective variable `UCI` has a lot of values that are 97, 98, or 99, which means that we don't know if the person is or was in a Intensive Care Unit, we only need the values 1 and 2, which means that the patient was or wasn't in an Intensive Care Unit, respectively.\n",
        "\n",
        "So the next step is to trim our dataset by removing the rows that have 97, 98 or 99, leaving only 'Yes'/'No' for our objective variable."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_drop = [97,98,99]\r\n",
        "for element in arr_drop:\r\n",
        "    df.drop(df.loc[df['UCI']==element].index,inplace=True)\r\n",
        "\r\n",
        "print(df)\r\n",
        "print(\"--------------------------------------\")\r\n",
        "print(\"Classes count\")\r\n",
        "classes = pd.crosstab(index=df['UCI'],columns=\"count\")\r\n",
        "print(classes)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        FECHA_ACTUALIZACION ID_REGISTRO  ORIGEN  SECTOR  ENTIDAD_UM  SEXO  \\\n",
            "1                2021-05-09      z49a69       1      12          23     1   \n",
            "16               2021-05-09      z166d5       1      12           1     1   \n",
            "21               2021-05-09      z388cd       1      12          29     2   \n",
            "22               2021-05-09      z4533d       1      12          29     1   \n",
            "27               2021-05-09      z4494e       1      12           8     1   \n",
            "...                     ...         ...     ...     ...         ...   ...   \n",
            "6757282          2021-05-09      4b89bb       1      12          22     2   \n",
            "6757292          2021-05-09      7efdce       1       4           9     2   \n",
            "6757308          2021-05-09      d45a16       1       4          19     1   \n",
            "6757320          2021-05-09      d3d30f       2       6          28     1   \n",
            "6757347          2021-05-09      a7f5d8       1      12          18     1   \n",
            "\n",
            "         ENTIDAD_NAC  ENTIDAD_RES  MUNICIPIO_RES  TIPO_PACIENTE  ...  \\\n",
            "1                 23           23              4              2  ...   \n",
            "16                 1            1              1              2  ...   \n",
            "21                15           21            117              2  ...   \n",
            "22                21           21            117              2  ...   \n",
            "27                 8            8             37              2  ...   \n",
            "...              ...          ...            ...            ...  ...   \n",
            "6757282           22           22             14              2  ...   \n",
            "6757292            9            9             10              2  ...   \n",
            "6757308           19           19             39              2  ...   \n",
            "6757320           28           28             27              2  ...   \n",
            "6757347           18           18             17              2  ...   \n",
            "\n",
            "        OTRO_CASO TOMA_MUESTRA_LAB RESULTADO_LAB  TOMA_MUESTRA_ANTIGENO  \\\n",
            "1               1                2            97                      2   \n",
            "16              2                1             1                      2   \n",
            "21              1                2            97                      2   \n",
            "22              2                2            97                      2   \n",
            "27              1                1             1                      2   \n",
            "...           ...              ...           ...                    ...   \n",
            "6757282         2                1             1                      2   \n",
            "6757292         2                2            97                      2   \n",
            "6757308         2                1             2                      2   \n",
            "6757320         2                1             3                      2   \n",
            "6757347         2                1             3                      2   \n",
            "\n",
            "         RESULTADO_ANTIGENO  CLASIFICACION_FINAL  MIGRANTE  PAIS_NACIONALIDAD  \\\n",
            "1                        97                    2        99             México   \n",
            "16                       97                    3        99             México   \n",
            "21                       97                    1        99             México   \n",
            "22                       97                    6        99             México   \n",
            "27                       97                    3        99             México   \n",
            "...                     ...                  ...       ...                ...   \n",
            "6757282                  97                    3        99             México   \n",
            "6757292                  97                    6        99             México   \n",
            "6757308                  97                    7        99             México   \n",
            "6757320                  97                    6        99             México   \n",
            "6757347                  97                    6        99             México   \n",
            "\n",
            "         PAIS_ORIGEN  UCI  \n",
            "1               97.0    1  \n",
            "16              97.0    2  \n",
            "21              97.0    2  \n",
            "22              97.0    2  \n",
            "27              97.0    2  \n",
            "...              ...  ...  \n",
            "6757282         97.0    2  \n",
            "6757292         97.0    2  \n",
            "6757308         97.0    2  \n",
            "6757320         97.0    1  \n",
            "6757347         97.0    2  \n",
            "\n",
            "[740781 rows x 40 columns]\n",
            "--------------------------------------\n",
            "Classes count\n",
            "col_0   count\n",
            "UCI          \n",
            "1       54892\n",
            "2      685889\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619155236
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining useful features\n",
        "As we defined in our task definition in the `README.md` file, we will use only the following features: `SEXO`, `EDAD`, `NEUMONIA`, `DIABETES`, `EPOC`, `ASMA`, `INMUSUPR`, `HIPERTENSION`, `OTRA_COM`, `CARDIOVASCULAR`, `OBESIDAD`, `RENAL_CRONICA`, `TABAQUISMO`, `RESULTADO_LAB`."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['SEXO', 'EDAD','NEUMONIA','DIABETES','EPOC','ASMA','INMUSUPR','HIPERTENSION','OTRA_COM','CARDIOVASCULAR','OBESIDAD','RENAL_CRONICA','TABAQUISMO','RESULTADO_LAB', 'UCI']]\r\n",
        "print(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         SEXO  EDAD  NEUMONIA  DIABETES  EPOC  ASMA  INMUSUPR  HIPERTENSION  \\\n",
            "1           1    66         1         1     2     2         2             1   \n",
            "16          1    32         1         1     2     2         2             1   \n",
            "21          2    12         1         1     2     2         2             2   \n",
            "22          1    11         2         1     2     2         2             2   \n",
            "27          1    49         2         2     2     2         2             2   \n",
            "...       ...   ...       ...       ...   ...   ...       ...           ...   \n",
            "6757282     2    87         1         2     2     2         2             2   \n",
            "6757292     2    21         2         2     2     2         2             2   \n",
            "6757308     1    69         2         2     2     2         2             2   \n",
            "6757320     1    70         2         2     1     2         1             1   \n",
            "6757347     1    33         1         2     2     2         2             2   \n",
            "\n",
            "         OTRA_COM  CARDIOVASCULAR  OBESIDAD  RENAL_CRONICA  TABAQUISMO  \\\n",
            "1               2               2         1              2           2   \n",
            "16              2               2         2              2           2   \n",
            "21              2               2         2              2           2   \n",
            "22              2               2         1              2           2   \n",
            "27              2               2         2              2           2   \n",
            "...           ...             ...       ...            ...         ...   \n",
            "6757282         2               2         2              2           2   \n",
            "6757292         2               2         2              2           2   \n",
            "6757308         2               2         2              2           2   \n",
            "6757320         2               1         2              1           2   \n",
            "6757347         2               2         1              2           2   \n",
            "\n",
            "         RESULTADO_LAB  UCI  \n",
            "1                   97    1  \n",
            "16                   1    2  \n",
            "21                  97    2  \n",
            "22                  97    2  \n",
            "27                   1    2  \n",
            "...                ...  ...  \n",
            "6757282              1    2  \n",
            "6757292             97    2  \n",
            "6757308              2    2  \n",
            "6757320              3    1  \n",
            "6757347              3    2  \n",
            "\n",
            "[740781 rows x 15 columns]\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619161658
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Handling dataset class imbalance\n",
        "\n",
        "As we can see, the rows with 1 (Yes) in the `UCI` column are a lot less than the 2 (No). we can send the dataset to training like this, but we will get a \"Class balancing warning\" alert in Azure ML, so we are going to fix it.\n",
        "\n",
        "The next step in our data preprocessing is to balance the dataset. We will need the `imblearn` library that we installed before, and we will need to divide our dataframe in X and y to use the \"RandomUnderSampler\" method.\n",
        "\n",
        "`y` has only the column `UCI` column, and `X` the rest of the columns, as we already defined the features we wanted in the previous cell"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['UCI']\n",
        "X = df.drop('UCI',1)\n",
        "\n",
        "rus = RandomUnderSampler(random_state = 42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X,y)\n",
        "print(X_resampled)\n",
        "print(\"-------\")\n",
        "print(y_resampled)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        SEXO  EDAD  NEUMONIA  DIABETES  EPOC  ASMA  INMUSUPR  HIPERTENSION  \\\n",
            "0          1    66         1         1     2     2         2             1   \n",
            "1          2    60         1         1     2     2         2             2   \n",
            "2          1    80         1         1     2     2         2             1   \n",
            "3          1     5         1         2     2     2         2             2   \n",
            "4          1    58         1         2     2     2         2             2   \n",
            "...      ...   ...       ...       ...   ...   ...       ...           ...   \n",
            "109779     2    15         2         2     2     2         2             2   \n",
            "109780     2    86         2         2     2     2         2             1   \n",
            "109781     2    61         1         1     2     2         2             1   \n",
            "109782     2    63         1         2     2     2         2             1   \n",
            "109783     1    49         1         2     2     2         2             2   \n",
            "\n",
            "        OTRA_COM  CARDIOVASCULAR  OBESIDAD  RENAL_CRONICA  TABAQUISMO  \\\n",
            "0              2               2         1              2           2   \n",
            "1              2               2         2              2           2   \n",
            "2              2               2         1              2           2   \n",
            "3              2               2         2              2           2   \n",
            "4              2               2         2              2           2   \n",
            "...          ...             ...       ...            ...         ...   \n",
            "109779         1               2         2              2           2   \n",
            "109780         2               2         2              2           2   \n",
            "109781         2               2         2              2           2   \n",
            "109782         2               2         1              2           2   \n",
            "109783         2               2         2              2           2   \n",
            "\n",
            "        RESULTADO_LAB  \n",
            "0                  97  \n",
            "1                   1  \n",
            "2                   4  \n",
            "3                  97  \n",
            "4                   2  \n",
            "...               ...  \n",
            "109779              2  \n",
            "109780             97  \n",
            "109781              4  \n",
            "109782              1  \n",
            "109783              1  \n",
            "\n",
            "[109784 rows x 14 columns]\n",
            "-------\n",
            "0         1\n",
            "1         1\n",
            "2         1\n",
            "3         1\n",
            "4         1\n",
            "         ..\n",
            "109779    2\n",
            "109780    2\n",
            "109781    2\n",
            "109782    2\n",
            "109783    2\n",
            "Name: UCI, Length: 109784, dtype: int64\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619176623
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/test split\r\n",
        "\r\n",
        "Now that we have our balanced data, we will divide X and y between train and test"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_resampled,y_resampled,test_size = 0.2, random_state = 42)\n",
        "\n",
        "train_data = pd.concat([x_train,y_train],axis=1)\n",
        "\n",
        "print(train_data)\n",
        "\n",
        "print(\"Validating that we have balanced data for training.\")\n",
        "classes = pd.crosstab(index=train_data['UCI'],columns=\"count\")\n",
        "print(classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        SEXO  EDAD  NEUMONIA  DIABETES  EPOC  ASMA  INMUSUPR  HIPERTENSION  \\\n",
            "29634      1    23         1         2     2     2         2             2   \n",
            "106415     2    74         1         1     2     2         2             1   \n",
            "78580      1    71         2         1     2     2         2             1   \n",
            "45877      2    34         1         2     2     2         2             2   \n",
            "524        2    33         1         2     2     2         2             2   \n",
            "...      ...   ...       ...       ...   ...   ...       ...           ...   \n",
            "54886      1    49         2         2     2     2         2             1   \n",
            "76820      2    63         2         2     2     2         2             2   \n",
            "103694     2    56         2         1     2     2         2             1   \n",
            "860        2    46         1         2     2     2         2             2   \n",
            "15795      2    32         2         2     2     2         2             2   \n",
            "\n",
            "        OTRA_COM  CARDIOVASCULAR  OBESIDAD  RENAL_CRONICA  TABAQUISMO  \\\n",
            "29634          2               2         2              2           2   \n",
            "106415         2               1         2              2           1   \n",
            "78580          2               2         2              2           2   \n",
            "45877          2               2         2              2           2   \n",
            "524            2               2         2              2           2   \n",
            "...          ...             ...       ...            ...         ...   \n",
            "54886          2               2         2              2           2   \n",
            "76820          2               2         2              2           2   \n",
            "103694         2               2         2              1           2   \n",
            "860            2               2         2              2           2   \n",
            "15795          2               2         1              2           2   \n",
            "\n",
            "        RESULTADO_LAB  UCI  \n",
            "29634               1    1  \n",
            "106415              2    2  \n",
            "78580              97    2  \n",
            "45877               1    1  \n",
            "524                 1    1  \n",
            "...               ...  ...  \n",
            "54886               2    1  \n",
            "76820              97    2  \n",
            "103694              4    2  \n",
            "860                 1    1  \n",
            "15795               1    1  \n",
            "\n",
            "[87827 rows x 15 columns]\n",
            "Validating that we have balanced data for training.\n",
            "col_0  count\n",
            "UCI         \n",
            "1      43805\n",
            "2      44022\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619498051
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Train Data to Tabular Dataset\r\n",
        "Since the train data is in the pandas Dataframe format, we have to convert it to Tabular Dataset to be used in AutoML\r\n",
        "\r\n",
        "Warning: don't forget to drop the dataframe index, as the csv creates another index, and it will confuse our model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert train_data (Which are in pandas DataFrame format) to TabularDataset format.\r\n",
        "try:\r\n",
        "    os.makedirs('./data', exist_ok=True)\r\n",
        "except OSError as error:\r\n",
        "    print('New directory cannot be created')\r\n",
        "    \r\n",
        "path = 'data/traindata.csv'\r\n",
        "train_data.to_csv(path, index= False)\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()\r\n",
        "datastore.upload(src_dir='data', target_path='data')\r\n",
        "\r\n",
        "train_data = TabularDatasetFactory.from_delimited_files(path=[(datastore, ('data/traindata.csv'))])\r\n",
        "print(\"Successfully converted the dataset to TabularDataset format.\")\r\n",
        "print(type(train_data))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 5 files\n",
            "Target already exists. Skipping upload for data/train.csv\n",
            "Target already exists. Skipping upload for data/train2.csv\n",
            "Target already exists. Skipping upload for data/train3.csv\n",
            "Target already exists. Skipping upload for data/trainBalanced.csv\n",
            "Uploading data/traindata.csv\n",
            "Uploaded data/traindata.csv, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n",
            "Successfully converted the dataset to TabularDataset format.\n",
            "<class 'azureml.data.tabular_dataset.TabularDataset'>\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1620619541339
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
        "\n",
        "Since I was dealing with a large dataset, I needed to give more time to the experiment_timeout_minutes, that's why it's set to 1 hour."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 60,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'accuracy'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target=compute_target,\n",
        "    task = \"classification\",\n",
        "    training_data=train_data,\n",
        "    label_column_name='UCI',   \n",
        "    enable_early_stopping= True,\n",
        "    featurization= 'auto',\n",
        "    debug_log = \"automl_errors.log\",\n",
        "    **automl_settings\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1620620087165
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit the experiment with RunDetails widget\n",
        "With the `RunDetails` widget we can see important outputs and when the run is completed.\n",
        "\n",
        "In this cell we submit the experiment, with `show_output = True` to see the run logs in real time"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(remote_run).show()\n",
        "#Submit the experiment\n",
        "remote_run = experiment.submit(automl_config, show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting remote run.\n",
            "No run_configuration provided, running on cpu-cluster with default configuration\n",
            "Running on remote compute: cpu-cluster\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automlcovid</td><td>AutoML_de361d0a-2f6f-4000-90b9-4cd588c5c22f</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_de361d0a-2f6f-4000-90b9-4cd588c5c22f?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-144339/workspaces/quick-starts-ws-144339&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Train-Test data split\n",
            "STATUS:       DONE\n",
            "DESCRIPTION:  Your input data has been split into a training dataset and a holdout test dataset for validation of the model. The test holdout dataset reflects the original distribution of your input data.\n",
            "              \n",
            "DETAILS:      \n",
            "+---------------------------------+---------------------------------+---------------------------------+\n",
            "|Dataset                          |Row counts                       |Percentage                       |\n",
            "+=================================+=================================+=================================+\n",
            "|train                            |79044                            |89.99965841939267                |\n",
            "|test                             |8783                             |10.00034158060733                |\n",
            "+---------------------------------+---------------------------------+---------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:47       0.6399    0.6399\n",
            "         4   MaxAbsScaler RandomForest                      0:00:51       0.6402    0.6402\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:00:56       0.6409    0.6409\n",
            "         2   MaxAbsScaler RandomForest                      0:00:46       0.6379    0.6409\n",
            "         3   MaxAbsScaler RandomForest                      0:01:33       0.6235    0.6409\n",
            "         6   StandardScalerWrapper XGBoostClassifier        0:01:46       0.6371    0.6409\n",
            "         5   MaxAbsScaler RandomForest                      0:01:52       0.6368    0.6409\n",
            "         8   SparseNormalizer XGBoostClassifier             0:00:54       0.6384    0.6409\n",
            "         9   SparseNormalizer XGBoostClassifier             0:00:55       0.6383    0.6409\n",
            "        10   SparseNormalizer XGBoostClassifier             0:00:51       0.6391    0.6409\n",
            "         7   MaxAbsScaler RandomForest                      0:02:11       0.6384    0.6409\n",
            "        11   SparseNormalizer XGBoostClassifier             0:00:52       0.6382    0.6409\n",
            "        12   MaxAbsScaler RandomForest                      0:00:51       0.6310    0.6409\n",
            "        13   MaxAbsScaler LightGBM                          0:00:48       0.6365    0.6409\n",
            "        14   MaxAbsScaler LightGBM                          0:00:52       0.6360    0.6409\n",
            "        16   MaxAbsScaler LightGBM                          0:00:42       0.6381    0.6409\n",
            "        18   SparseNormalizer XGBoostClassifier             0:00:47       0.6387    0.6409\n",
            "        15   MaxAbsScaler ExtremeRandomTrees                0:01:24       0.6280    0.6409\n",
            "        17   MaxAbsScaler ExtremeRandomTrees                0:01:39       0.6310    0.6409\n",
            "        19   MaxAbsScaler RandomForest                      0:00:51       0.6297    0.6409\n",
            "        20   MaxAbsScaler LightGBM                          0:00:45       0.6279    0.6409\n",
            "        21   StandardScalerWrapper LightGBM                 0:00:49       0.6330    0.6409\n",
            "        22   SparseNormalizer LightGBM                      0:00:43       0.6281    0.6409\n",
            "        24   StandardScalerWrapper LightGBM                 0:00:46       0.6283    0.6409\n",
            "        25   StandardScalerWrapper XGBoostClassifier        0:00:44       0.5012    0.6409\n",
            "        23   MaxAbsScaler ExtremeRandomTrees                0:01:20       0.6318    0.6409\n",
            "        26   MaxAbsScaler ExtremeRandomTrees                0:00:52       0.6279    0.6409\n",
            "        27   SparseNormalizer LightGBM                      0:00:48       0.6321    0.6409\n",
            "        28   MaxAbsScaler LogisticRegression                0:00:48       0.6403    0.6409\n",
            "        29   MaxAbsScaler LogisticRegression                0:00:54       0.6403    0.6409\n",
            "        30   SparseNormalizer XGBoostClassifier             0:01:01       0.6359    0.6409\n",
            "        31   MaxAbsScaler LogisticRegression                0:00:54       0.6403    0.6409\n",
            "        32   MaxAbsScaler LogisticRegression                0:00:50       0.6403    0.6409\n",
            "        33   MaxAbsScaler LogisticRegression                0:00:51       0.6396    0.6409\n",
            "        34   StandardScalerWrapper XGBoostClassifier        0:00:26          nan    0.6409\n",
            "        35   SparseNormalizer XGBoostClassifier             0:00:21          nan    0.6409\n",
            "        36                                                  0:00:34          nan    0.6409\n",
            "        37                                                  0:00:15          nan    0.6409\n",
            "        38    VotingEnsemble                                0:00:59       0.6420    0.6420\n",
            "        39    StackEnsemble                                 0:01:32       0.6399    0.6420\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1620621245591
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "In the cell below we get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run_automl, fitted_model_automl = remote_run.get_output()\r\n",
        "\r\n",
        "#Displaying properties of the AutoML Model\r\n",
        "print(\"AutoML:\")\r\n",
        "automl_best_run_metrics = best_run_automl.get_metrics()\r\n",
        "print(\"Best run Id: \",best_run_automl.id)\r\n",
        "print(\"Accuracy: \", automl_best_run_metrics['accuracy'])\r\n",
        "print(\"All metrics:\")\r\n",
        "for metric in automl_best_run_metrics:\r\n",
        "    value = automl_best_run_metrics[metric]\r\n",
        "    print(metric,value)\r\n",
        "#Saving the best model\r\n",
        "model_automl = best_run_automl.register_model(model_path='./outputs/', model_name='model_automl.pkl')\r\n",
        "print(\"\\nModel saved successfully\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The model you attempted to retrieve requires 'azureml-train-automl-runtime' to be installed at '==1.27.0.post1'. Please install 'azureml-train-automl-runtime==1.27.0.post1' (e.g. `pip install azureml-train-automl-runtime==1.27.0.post1`) and then rerun the previous command.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML:\n",
            "Best run Id:  AutoML_de361d0a-2f6f-4000-90b9-4cd588c5c22f_38\n",
            "Accuracy:  0.6420357508823864\n",
            "All metrics:\n",
            "AUC_weighted 0.684852452885799\n",
            "f1_score_weighted 0.6351655361242334\n",
            "log_loss 0.6358452360325219\n",
            "AUC_micro 0.6915708695789867\n",
            "average_precision_score_macro 0.673512427213038\n",
            "average_precision_score_micro 0.6808832612149752\n",
            "weighted_accuracy 0.6417067693627544\n",
            "balanced_accuracy 0.6423647361634816\n",
            "accuracy 0.6420357508823864\n",
            "norm_macro_recall 0.2847294723269631\n",
            "average_precision_score_weighted 0.6735466258642014\n",
            "precision_score_weighted 0.6540698467413734\n",
            "f1_score_micro 0.6420357508823864\n",
            "recall_score_micro 0.6420357508823864\n",
            "AUC_macro 0.6848524528857989\n",
            "precision_score_micro 0.6420357508823864\n",
            "matthews_correlation 0.2961034924403513\n",
            "f1_score_macro 0.6352841829251554\n",
            "precision_score_macro 0.6539659339070646\n",
            "recall_score_weighted 0.6420357508823864\n",
            "recall_score_macro 0.6423647361634816\n",
            "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_de361d0a-2f6f-4000-90b9-4cd588c5c22f_38/accuracy_table\n",
            "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_de361d0a-2f6f-4000-90b9-4cd588c5c22f_38/confusion_matrix\n",
            "\n",
            "Model saved successfully\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1620622256129
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying the fitted model properties\n",
        "print_model(fitted_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service.\n",
        "\n",
        "Before this step we have to run the `hyperparameter_tuning.ipynb`  notebook, in this case we determined that the model with the most accuracy was the one from AutoML. The next step is to deploy the model and test it.\n",
        "\n",
        "First we have to download the scoring file and the environment file, this can be obtained from the best run."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Download scoring file \r\n",
        "best_run_automl.download_file('outputs/scoring_file_v_1_0_0.py', 'scoring.py')"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1620626604700
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to deploy the model with inference configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "#Configuration for inference\r\n",
        "inference_config = InferenceConfig(entry_script='scoring.py',\r\n",
        "                                    environment=best_run_automl.get_environment())\r\n",
        "\r\n",
        "#Deployment configuration\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\r\n",
        "service = model_automl.deploy(ws, \"automlcovid\", [model_automl], inference_config, deployment_config)\r\n",
        "service.wait_for_deployment(show_output = True)\r\n",
        "print(\"Service state:\")\r\n",
        "print(service.state)\r\n",
        "print(\"Scoring URI:\")\r\n",
        "print(service.scoring_uri)\r\n",
        "print(\"Swagger URI:\")\r\n",
        "print(service.swagger_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-05-10 06:07:27+00:00 Creating Container Registry if not exists..\n",
            "2021-05-10 06:07:38+00:00 Registering the environment..\n",
            "2021-05-10 06:07:39+00:00 Use the existing image.\n",
            "2021-05-10 06:07:39+00:00 Generating deployment configuration.\n",
            "2021-05-10 06:07:41+00:00 Submitting deployment to compute..\n",
            "2021-05-10 06:07:44+00:00 Checking the status of deployment automlcovid..\n",
            "2021-05-10 06:10:59+00:00 Checking the status of inference endpoint automlcovid.\n",
            "Failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:azureml.core.webservice.webservice:Service deployment polling reached non-successful terminal state, current service state: Failed\n",
            "Operation ID: 060a8f2c-2942-456c-a6ed-00c6f6ac6be6\n",
            "More information can be found using '.get_logs()'\n",
            "Error:\n",
            "{\n",
            "  \"code\": \"AciDeploymentFailed\",\n",
            "  \"statusCode\": 400,\n",
            "  \"message\": \"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\",\n",
            "  \"details\": [\n",
            "    {\n",
            "      \"code\": \"CrashLoopBackOff\",\n",
            "      \"message\": \"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 060a8f2c-2942-456c-a6ed-00c6f6ac6be6\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 060a8f2c-2942-456c-a6ed-00c6f6ac6be6\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ebf4d70cd76c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdeployment_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAciWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_cores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_gb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_automl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"automlcovid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_automl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Service state:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mlogs_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Current sub-operation type not known, more logs unavailable.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n\u001b[0m\u001b[1;32m    918\u001b[0m                                           \u001b[0;34m'service state: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                                           \u001b[0;34m'Operation ID: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 060a8f2c-2942-456c-a6ed-00c6f6ac6be6\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 060a8f2c-2942-456c-a6ed-00c6f6ac6be6\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models/model_automl.pkl/6/model.pkl', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the cell below we send a request to the web service we deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}